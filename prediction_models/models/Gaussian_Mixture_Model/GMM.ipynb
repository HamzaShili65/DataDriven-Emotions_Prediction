{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'YOUR DATA PATH'\n",
    "test_path = 'YOUR DATA PATH'\n",
    "\n",
    "# Set the number of Mel-Frequency Cepstral Coefficients (MFCCs) to extract.\n",
    "num_mfcc = 20\n",
    "\n",
    "# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Iterate through all of the .wav files in the training directory.\n",
    "for file in sorted(os.listdir(data_path)):\n",
    "    if file.endswith(\".wav\"):\n",
    "        # Load the audio file using librosa and our files in Google Drive.\n",
    "        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))\n",
    "\n",
    "        # Determine the MFCC features from the audio data provided above.\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)\n",
    "\n",
    "        # Grab the mean and standard deviation of our features.\n",
    "        mfccs_avg = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Add the MFCC features to the data matrix\n",
    "        X_train.append(np.concatenate((mfccs_avg, mfccs_std)))\n",
    "\n",
    "        # Determine the emotion label of the audio file based on its filename.\n",
    "        label = \"\"\n",
    "        idx = 0\n",
    "        while not (file[idx].isdigit()):\n",
    "            label += file[idx]\n",
    "            idx += 1\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split Data into Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our data into np.arrays\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "# Use stratified sampling to split the data into a smaller training set and a validation set\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed MFCC features and emotion labels\n",
    "#X = np.load('mfcc_features.npy')\n",
    "#y = np.load('emotion_labels.npy')\n",
    "\n",
    "# Split data into training and testing sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a GMM model for each emotion class\n",
    "n_components = 60\n",
    "covariance_type = 'full'\n",
    "emotion_classes = ['angry', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprise', 'calm']\n",
    "models = []\n",
    "#print(y_train == 'surprise')\n",
    "for emotion in emotion_classes:\n",
    "    #print(emotion)\n",
    "    # Get training data for current emotion class\n",
    "    X_emotion = X_train_new[y_train_new == emotion]\n",
    "    # Train a GMM model for current emotion class\n",
    "    model = GaussianMixture(n_components=n_components, reg_covar=1e-06, covariance_type=covariance_type)\n",
    "    if X_emotion.shape[0] != 0:\n",
    "         model.fit(X_emotion)\n",
    "         models.append(model)\n",
    "\n",
    "# Classify testing data using the trained GMM models\n",
    "y_pred = []\n",
    "for mfcc in X_val:\n",
    "    likelihoods = []\n",
    "    for model in models:\n",
    "        # Calculate likelihood of mfcc belonging to current emotion class\n",
    "        likelihood = np.exp(model.score(mfcc.reshape(1, -1)))\n",
    "        likelihoods.append(likelihood)\n",
    "    # Assign emotion class with highest likelihood as predicted emotion\n",
    "    pred_emotion = emotion_classes[np.argmax(likelihoods)]\n",
    "    y_pred.append(pred_emotion)\n",
    "\n",
    "# Evaluate performance of the GMM classifier\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "# Print the classification report and confusion matrix for the validation set\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test: Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_test = []\n",
    "file_names = []\n",
    "for file in sorted(os.listdir(test_path)):\n",
    "    if file.endswith(\".wav\"):\n",
    "\n",
    "        file_names.append(file.split(\".\")[0])\n",
    "\n",
    "        # Load the audio file using librosa and our files in Google Drive.\n",
    "        audio_data, sample_rate = librosa.load(os.path.join(test_path, file))\n",
    "\n",
    "        # Determine the MFCC features from the audio data provided above.\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)\n",
    "\n",
    "        # Grab the mean and standard deviation of our features.\n",
    "        mfccs_avg = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Add the MFCC features to the data matrix\n",
    "        X_test.append(np.concatenate((mfccs_avg.reshape(-1), mfccs_std.reshape(-1))))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Predict the labels of the test data using the trained SVM classifier\n",
    "#y_pred_test = svm_classifier.predict(X_test)\n",
    "# Classify testing data using the trained GMM models\n",
    "y_pred_test = []\n",
    "for mfcc in X_test:\n",
    "    likelihoods = []\n",
    "    for model in models:\n",
    "        # Calculate likelihood of mfcc belonging to current emotion class\n",
    "        likelihood = np.exp(model.score(mfcc.reshape(1, -1)))\n",
    "        likelihoods.append(likelihood)\n",
    "    # Assign emotion class with highest likelihood as predicted emotion\n",
    "    pred_emotion = emotion_classes[np.argmax(likelihoods)]\n",
    "    y_pred_test.append(pred_emotion)\n",
    "\n",
    "# Convert the file names and predicted labels to a two-dimensional numpy array\n",
    "predictions = np.column_stack((file_names, y_pred_test))\n",
    "\n",
    "# Sort the predictions array by the first column (the sorted file names)\n",
    "predictions = predictions[np.lexsort((predictions[:, 0],))]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "np.savetxt(\"predictions.csv\", predictions, fmt='%s', delimiter=\",\", encoding='utf-8')\n",
    "with open(\"predictions.csv\", \"r+\") as f:\n",
    "    content = f.read()\n",
    "    f.seek(0, 0)\n",
    "    f.write(\"filename,Label\\n\" + content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
