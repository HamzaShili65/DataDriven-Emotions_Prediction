{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bayesian Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Set the number of Mel-Frequency Cepstral Coefficients (MFCCs) to extract.\n",
    "num_mfcc = 20\n",
    "\n",
    "# Initialize empty arrays to hold the feature matrix from audio and corresponding labels.\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# Iterate through all of the .wav files in the training directory.\n",
    "for file in sorted(os.listdir(data_path)):\n",
    "    if file.endswith(\".wav\"):\n",
    "        # Load the audio file using librosa and our files in Google Drive.\n",
    "        audio_data, sample_rate = librosa.load(os.path.join(data_path, file))\n",
    "\n",
    "        # Determine the MFCC features from the audio data provided above.\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)\n",
    "\n",
    "\n",
    "        # Grab the mean and standard deviation of our features.\n",
    "        mfccs_avg = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Add the MFCC features to the data matrix\n",
    "        X_train.append(np.concatenate((mfccs_avg, mfccs_std)))\n",
    "\n",
    "        # Determine the emotion label of the audio file based on its filename.\n",
    "        label = \"\"\n",
    "        idx = 0\n",
    "        while not (file[idx].isdigit()):\n",
    "            label += file[idx]\n",
    "            idx += 1\n",
    "        y_train.append(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "params = {\n",
    "    \"C\": Real(1e-6, 1e+6, prior=\"log-uniform\"),\n",
    "    \"gamma\": Real(1e-6, 1e+1, prior=\"log-uniform\"),\n",
    "    \"kernel\": Categorical([\"poly\", \"sigmoid\"]),\n",
    "    \"degree\": Integer(1, 5),\n",
    "    \"coef0\": Real(-1, 1)\n",
    "}\n",
    "\n",
    "# Initialize the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Define the Skopt hyperparameter search\n",
    "skopt_search = BayesSearchCV(\n",
    "    svm_classifier,\n",
    "    params,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Apply feature scaling to the dataset\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "#X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Perform the hyperparameter search with Skopt\n",
    "#skopt_search.fit(X_train, y_train)\n",
    "skopt_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best hyperparameters and score found by Skopt\n",
    "print(\"Best parameters:\", skopt_search.best_params_)\n",
    "print(\"Best score:\", skopt_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM classifier with the best hyperparameters found by Skopt\n",
    "svm_classifier = SVC(C=skopt_search.best_params_['C'], gamma=skopt_search.best_params_['gamma'], kernel=skopt_search.best_params_['kernel'])\n",
    "\n",
    "# Use stratified sampling to split the data into a smaller training set and a validation set\n",
    "X_train_new, X_val, y_train_new, y_val = train_test_split(\n",
    "     X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
    "\n",
    "svm_classifier.fit(X_train_new, y_train_new)\n",
    "\n",
    "\n",
    "# Predict the labels of the validation set using the trained SVM classifier\n",
    "y_pred_val = svm_classifier.predict(X_val)\n",
    "\n",
    "# Predict the labels of the validation set using the trained SVM classifier\n",
    "y_pred_val = svm_classifier.predict(X_val)\n",
    "\n",
    "# Print the classification report and confusion matrix for the validation set\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "print(confusion_matrix(y_val, y_pred_val))\n",
    "\n",
    "# Predict the labels of the test data using the trained SVM classifier\n",
    "X_test = []\n",
    "file_names = []\n",
    "for file in sorted(os.listdir(test_path)):\n",
    "    if file.endswith(\".wav\"):\n",
    "\n",
    "        file_names.append(file.split(\".\")[0])\n",
    "\n",
    "        # Load the audio file using librosa and our files in Google Drive.\n",
    "        audio_data, sample_rate = librosa.load(os.path.join(test_path, file))\n",
    "\n",
    "        # Determine the MFCC features from the audio data provided above.\n",
    "        mfccs = librosa.feature.mfcc(y=audio_data, sr=sample_rate, n_mfcc=num_mfcc)\n",
    "\n",
    "        # Grab the mean and standard deviation of our features.\n",
    "        mfccs_avg = np.mean(mfccs, axis=1)\n",
    "        mfccs_std = np.std(mfccs, axis=1)\n",
    "\n",
    "        # Add the MFCC features to the data matrix\n",
    "        X_test.append(np.concatenate((mfccs_avg.reshape(-1), mfccs_std.reshape(-1))))\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "# Predict the labels of the test data using the trained SVM classifier\n",
    "y_pred_test = svm_classifier.predict(X_test)\n",
    "\n",
    "# Convert the file names and predicted labels to a two-dimensional numpy array\n",
    "predictions = np.column_stack((file_names, y_pred_test))\n",
    "\n",
    "# Sort the predictions array by the first column (the sorted file names)\n",
    "predictions = predictions[np.lexsort((predictions[:, 0],))]\n",
    "\n",
    "# Save the predictions to a CSV file\n",
    "np.savetxt(\"predictions.csv\", predictions, fmt='%s', delimiter=\",\", encoding='utf-8')\n",
    "with open(\"predictions.csv\", \"r+\") as f:\n",
    "    content = f.read()\n",
    "    f.seek(0, 0)\n",
    "    f.write(\"filename,Label\\n\" + content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
